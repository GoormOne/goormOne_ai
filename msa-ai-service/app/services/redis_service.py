import asyncio
import logging
import redis
import socket
from datetime import datetime
from app.db.mongodb import get_collection
from app.core.config import (
    REDIS_HOST, REDIS_PORT,
    REDIS_REQUEST_STREAM, REDIS_RESPONSE_STREAM, MONGODB_NAME
)
from app.services.embedding_service import EmbeddingService
from app.services.rag_service import RagService

logger = logging.getLogger(__name__)

r = redis.Redis(
    host=REDIS_HOST,
    port=REDIS_PORT,
    decode_responses=True,
    encoding='utf-8'
)

GROUP_NAME = "ai-service"
CONSUMER_NAME = "fastapi-worker"
# CONSUMER_NAME = f"fastapi-{socket.gethostname()}"

queries_col = get_collection("queries")

embedding_svc = EmbeddingService()
rag_svc = RagService()


# ---------------------------
# Consumer ì—­í• 
# ---------------------------
def init_consumer_group():
    """Redis Consumer Group ì´ˆê¸°í™”"""
    try:
        r.xgroup_create(
            REDIS_REQUEST_STREAM,
            GROUP_NAME,
            id="$",
            mkstream=True
        )
        logger.info("âœ… Redis consumer group created")

    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP" in str(e):
            logger.info("â„¹ï¸ Consumer group already exists")
        else:
            raise


def read_request():
    """Redis Streamì—ì„œ ìƒˆ ìš”ì²­ ì½ê¸°"""
    msgs = r.xreadgroup(
        GROUP_NAME,
        CONSUMER_NAME,
        {REDIS_REQUEST_STREAM: ">"},
        count=1,
        block=5000
    )

    logger.info(f"ğŸ“¦ Raw msgs: {msgs}")

    if not msgs:
        return None, None

    stream, elements = msgs[0]
    for msg_id, fields in elements:
        logger.info(f"ğŸ“¥ Received from {stream}: id={msg_id}, fields={fields}")
        return msg_id, fields

    return None, None


# ---------------------------
# Producer ì—­í• 
# ---------------------------
def add_request(request_id: str, store_id: str, menu_id: str, query: str):
    """FastAPIì—ì„œ ì§ì ‘ Redis ìš”ì²­ ìŠ¤íŠ¸ë¦¼ì— ë©”ì‹œì§€ ì¶”ê°€"""
    return r.xadd(REDIS_REQUEST_STREAM, {
        "request_id": request_id,
        "store_id": store_id,
        "menu_id": menu_id,
        "query": query
    })


def add_response(request_id: str, answer: str, source: str = "generated"):
    """FastAPIê°€ ìƒì„±í•œ ì‘ë‹µì„ Redis ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì— push"""
    r.xadd(REDIS_RESPONSE_STREAM, {
        "request_id": request_id,
        "answer": answer,
        "source": source
    })
    logger.info(f"âœ… Response pushed for {request_id}")


# ---------------------------
# Worker Loop
# ---------------------------
async def worker_loop():
    """Redis Worker Loop"""
    while True:
        msg_id, msg = read_request()
        if msg:
            try:
                logger.info(f"ğŸ“¥ Processing message: {msg}")

                request_id = msg["request_id"]
                store_id = msg["store_id"]
                menu_id = msg["menu_id"]
                query = msg.get("query")

                # 1. MongoDB ì €ì¥
                result = queries_col.update_one(
                    {"_id": store_id, "menus.menu_id": menu_id},
                    {
                        "$push": {"menus.$.queries": {
                            "query_id": request_id,
                            "query": query
                        }},
                        "$set": {"updated_at": datetime.utcnow()}
                    }
                )

                if result.matched_count == 0:
                    queries_col.update_one(
                        {"_id": store_id},
                        {
                            "$push": {
                                "menus": {
                                    "menu_id": menu_id,
                                    "queries": [{
                                        "query_id": request_id,
                                        "query": query
                                    }]
                                }
                            },
                            "$set": {"updated_at": datetime.utcnow()}
                        },
                        upsert=True
                    )
                    logger.info(f"ğŸ†• New menu created: store={store_id}, menu={menu_id}")
                else:
                    logger.info(f"â• Query pushed: store={store_id}, menu={menu_id}")

                logger.info(
                    f"âœ… Saved to MongoDB: store={store_id}, menu={menu_id}, request={request_id}, db={MONGODB_NAME}"
                )

                # 2. gRPCë¡œ model-service í˜¸ì¶œ â†’ ì„ë² ë”©/ë¼ë²¨ë§
                meta = {"type": "query", "query_id": request_id, "store_id": store_id, "menu_id": menu_id}
                embedding_svc.embed_and_label(query, meta)

                # 3. RAG ì‹¤í–‰ â†’ answers ì €ì¥
                answer = rag_svc.run_rag(request_id, store_id, menu_id)

                # 4. Redis ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ push
                add_response(request_id, answer)

                # âœ… ëª¨ë“  ì‘ì—… ì„±ê³µ í›„ ack
                r.xack(REDIS_REQUEST_STREAM, GROUP_NAME, msg_id)
                logger.info(f"ğŸ‘ Acked message {msg_id}")

            except Exception as e:
                logger.error(f"âŒ Worker ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)

        await asyncio.sleep(0.1)


def start_redis_consumer():
    """FastAPI lifespanì—ì„œ í˜¸ì¶œ"""
    init_consumer_group()
    asyncio.create_task(worker_loop())
    logger.info("ğŸš€ Redis consumer started")


# # ë ˆë””ìŠ¤ ì»¨ìŠˆë¨¸ + í”„ë¡œë“€ì„œ
# # ì„ì‹œí…ŒìŠ¤íŠ¸ ì™„ë£Œ

# import asyncio
# import logging
# import redis
# import socket
# from datetime import datetime
# from app.db.mongodb import get_collection
# from app.core.config import (
#     REDIS_HOST, REDIS_PORT,
#     REDIS_REQUEST_STREAM, REDIS_RESPONSE_STREAM, MONGODB_NAME
# )
# from app.services.embedding_service import EmbeddingService
# from app.services.rag_service import RagService

# logger = logging.getLogger(__name__)

# r = redis.Redis(
#                 host=REDIS_HOST, 
#                 port=REDIS_PORT, 
#                 decode_responses=True, 
#                 encoding='utf-8')

# GROUP_NAME = "ai-service"
# CONSUMER_NAME = "fastapi-worker"    
# # CONSUMER_NAME = f"fastapi-{socket.gethostname()}"

# queries_col = get_collection("queries")

# embedding_svc = EmbeddingService()
# rag_svc = RagService()


# # ---------------------------
# # Consumer ì—­í• 
# # ---------------------------
# last_id = "0"
# def init_consumer_group():
#     """Redis Consumer Group ì´ˆê¸°í™”"""
#     try:
#         r.xgroup_create(
#                         REDIS_REQUEST_STREAM, 
#                         GROUP_NAME, 
#                         id="$", 
#                         mkstream=True
#                         )
#         logger.info("âœ… Redis consumer group created")

#     except redis.exceptions.ResponseError as e:
#         if "BUSYGROUP" in str(e):
#             logger.info("â„¹ï¸ Consumer group already exists")
#         else:
#             raise
# def read_request():
#     msgs = r.xreadgroup(
#         GROUP_NAME,
#         CONSUMER_NAME,
#         {REDIS_REQUEST_STREAM: ">"},  # backlog í¬í•¨ ì „ë¶€ ì½ê¸°
#         count=1,
#         block=5000
#     )

#     logger.info(f"ğŸ“¦ Raw msgs: {msgs}")

#     if not msgs:
#         return None

#     stream, elements = msgs[0]
#     for msg_id, fields in elements:
#         logger.info(f"ğŸ“¥ Received from {stream}: id={msg_id}, fields={fields}")
#         r.xack(REDIS_REQUEST_STREAM, GROUP_NAME, msg_id)
#         return fields

# """
# def read_request():
#     global last_id

#     msgs = r.xreadgroup(
#         GROUP_NAME,
#         CONSUMER_NAME,
#         {REDIS_REQUEST_STREAM: last_id},
#         count=1,
#         block=5000
#     )

#     logger.info(f"ğŸ“¦ Raw msgs: {msgs}")  # ë¬´ì¡°ê±´ ì°ê¸°

#     if not msgs:
#         return None

#     stream, elements = msgs[0]
#     if not elements:
#         return None

#     msg_id, fields = elements[0]
#     logger.info(f"ğŸ“¦ Read from stream: id={msg_id}, fields={fields}")
#     r.xack(REDIS_REQUEST_STREAM, GROUP_NAME, msg_id)

#     if last_id == "0":
#         last_id = ">"

#     return fields

# """

# # def read_request():
# #     msgs = r.xreadgroup(
# #         GROUP_NAME,
# #         CONSUMER_NAME,
# #         {REDIS_REQUEST_STREAM: ">"},
# #         count=1,
# #         block=5000
# #     )
# #     logger.info(f"ğŸ“¦ Raw msgs: {msgs}")  

# #     if not msgs:
# #         return None
# #     msg_id, fields = msgs[0][1][0]

# #     # _, elements = msgs[0]
# #     # msg_id, fields = elements[0]
# #     logger.info(f"ğŸ“¦ Read from stream: id={msg_id}, fields={fields}")
# #     r.xack(REDIS_REQUEST_STREAM, GROUP_NAME, msg_id)
# #     return fields

# # def read_request(process_old = False):
# #     """Redis Streamì—ì„œ ìš”ì²­ ì½ê¸°"""
# #     last_id = "0" if process_old else ">"
# #     msgs = r.xreadgroup(
# #                         GROUP_NAME, 
# #                         CONSUMER_NAME, 
# #                         {REDIS_REQUEST_STREAM: "last_id"}, # >ë¡œ í•´ë³´ê¸° 
# #                         count=1, 
# #                         block=5000)
    
# #     if not msgs:
# #         logger.debug("â³ No new messages")
# #         return None
    
# #     _, elements = msgs[0]
# #     for msg_id, fields in elements:
# #         logger.info(f"ğŸ“¦ Read from stream: id={msg_id}, fields={fields}")
# #         r.xack(REDIS_REQUEST_STREAM, GROUP_NAME, msg_id)
# #         yield fields


# # ---------------------------
# # Producer ì—­í• 
# # ---------------------------
# def add_request(request_id: str, store_id: str, menu_id: str, query: str):
#     """
#     FastAPIì—ì„œ ì§ì ‘ Redis ìš”ì²­ ìŠ¤íŠ¸ë¦¼ì— ë©”ì‹œì§€ ì¶”ê°€ (í…ŒìŠ¤íŠ¸/ë‚´ë¶€ìš©)
#     """
#     return r.xadd(REDIS_REQUEST_STREAM, {
#         "request_id": request_id,
#         "store_id": store_id,
#         "menu_id": menu_id,
#         "query": query
#     })


# def add_response(request_id: str, answer: str, source: str = "generated"):
#     """
#     FastAPIê°€ ìƒì„±í•œ ì‘ë‹µì„ Redis ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì— push
#     """
#     return r.xadd(REDIS_RESPONSE_STREAM, {
#         "request_id": request_id,
#         "answer": answer
#     })
#     logger.info(f"âœ… Response pushed for {request_id}")



# # ---------------------------
# # Worker Loop
# # ---------------------------
# async def worker_loop():
#     """Redis Worker Loop"""
#     while True:
#         msg = read_request()
#         if msg:
#             logger.info(f"ğŸ“¥ Received: {msg}")

#             request_id = msg["request_id"]
#             store_id = msg["store_id"]
#             menu_id = msg["menu_id"]
#             query = msg.get("query")


#             # 1. ê¸°ì¡´ store + menu ì°¾ê³  ì§ˆë¬¸ push
#             result = queries_col.update_one(
#                 {"_id": store_id, "menus.menu_id": menu_id},
#                 {
#                     "$push": {
#                         "menus.$.queries": {
#                             "query_id": request_id,
#                             "query": query
#                         }
#                     },
#                     "$set": {"updated_at": datetime.utcnow()}
#                 }
#             )

#             # 1-2. store_id ë¬¸ì„œê°€ ì—†ê±°ë‚˜ menu_idê°€ ì—†ì„ ë•Œ â†’ ìƒˆë¡œ ìƒì„±
#             if result.matched_count == 0:
#                 queries_col.update_one(
#                     {"_id": store_id},
#                     {
#                         "$push": {
#                             "menus": {
#                                 "menu_id": menu_id,
#                                 "queries": [
#                                     {
#                                         "query_id": request_id,
#                                         "query": query
#                                     }
#                                 ]
#                             }
#                         },
#                         "$set": {"updated_at": datetime.utcnow()}
#                     },
#                     upsert=True
#                 )

#             logger.info(f"âœ… Saved to MongoDB: store={store_id}, menu={menu_id}, request={request_id}, db={MONGODB_NAME}")


#             # 2. gRPCë¡œ model-service í˜¸ì¶œ â†’ ì„ë² ë”©/ë¼ë²¨ë§ + queries_embedding ì €ì¥
#             meta = {"type": "query", "query_id": request_id, "store_id": store_id, "menu_id": menu_id}
#             embedding_svc.embed_and_label(query, meta)

#             # 3. RAG ì‹¤í–‰ â†’ answers ì €ì¥
#             answer = rag_svc.run_rag(request_id, store_id, menu_id)

#             # 4. Redis ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ push (Springì´ ì‚¬ìš©ìí•œí…Œ ì „ë‹¬)
#             add_response(request_id, answer)

            
#             # # ğŸ‘‰ ê°„ë‹¨íˆ í™•ì¸ë§Œ: ë°›ì€ ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì‘ë‹µ
#             # answer = f"'{query}'ì— ëŒ€í•œ ì„ì‹œ ì‘ë‹µì…ë‹ˆë‹¤."
#             # add_response(request_id, answer)

#         await asyncio.sleep(0.1)


# def start_redis_consumer():
#     """FastAPI lifespanì—ì„œ í˜¸ì¶œ"""
#     init_consumer_group()
#     asyncio.create_task(worker_loop())
#     logger.info("ğŸš€ Redis consumer started")